{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8930f0a7",
   "metadata": {},
   "source": [
    "# Text generation with LSTM: \n",
    "\n",
    "This notebook is from Lazy Programmer's 'poetry.py' from Advanced NLP course (nlp3).\n",
    "\n",
    "In this notebook, Robert Frost's poem 'The Road Not Taken' was used to train a single LSTM model to generate text. \n",
    "The architecture of the model consists of only 4 layers: an input layer, an embedding layer, a LSTM layer and a Dense layer for prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244918c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de8a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51b5a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import keras.backend as K\n",
    "  if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "    from keras.layers import CuDNNLSTM as LSTM\n",
    "    from keras.layers import CuDNNGRU as GRU\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2b3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some configuration\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 3000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200\n",
    "LATENT_DIM = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aade2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "for line in open('robert_frost.txt'):\n",
    "  line = line.rstrip()\n",
    "  if not line:\n",
    "    continue\n",
    "\n",
    "  input_line = '<sos> ' + line\n",
    "  target_line = line + ' <eos>'\n",
    "\n",
    "  input_texts.append(input_line)\n",
    "  target_texts.append(target_line)\n",
    "\n",
    "all_lines = input_texts + target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d7984dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two roads diverged in a yellow wood, <eos>',\n",
       " 'And sorry I could not travel both <eos>',\n",
       " 'And be one traveler, long I stood <eos>',\n",
       " 'And looked down one as far as I could <eos>',\n",
       " 'To where it bent in the undergrowth; <eos>',\n",
       " 'Then took the other, as just as fair, <eos>',\n",
       " 'And having perhaps the better claim <eos>',\n",
       " 'Because it was grassy and wanted wear, <eos>',\n",
       " 'Though as for that the passing there <eos>',\n",
       " 'Had worn them really about the same, <eos>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7703d2d0",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3d4d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = MAX_VOCAB_SIZE, filters='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6795f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_lines)\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36638eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[104, 537, 538, 9, 7, 539, 540, 2],\n",
       " [5, 541, 6, 65, 31, 934, 141, 2],\n",
       " [5, 27, 24, 935, 152, 6, 221, 2],\n",
       " [5, 167, 67, 24, 17, 128, 17, 6, 65, 2],\n",
       " [4, 40, 11, 936, 9, 3, 937, 2],\n",
       " [91, 189, 3, 542, 17, 77, 17, 938, 2],\n",
       " [5, 142, 265, 3, 222, 939, 2],\n",
       " [319, 11, 14, 543, 5, 223, 940, 2],\n",
       " [122, 17, 15, 13, 3, 544, 55, 2],\n",
       " [23, 545, 52, 404, 111, 3, 546, 2]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03bf3663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence is: 12\n"
     ]
    }
   ],
   "source": [
    "#find max seq length\n",
    "max_seq_len = max(len(s) for s in input_sequences)\n",
    "print('Max sequence is:', max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26fb5962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3056 unique tokens\n"
     ]
    }
   ],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "print('Found %s unique tokens' %len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce94b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<sos>', 1),\n",
       " ('<eos>', 2),\n",
       " ('the', 3),\n",
       " ('to', 4),\n",
       " ('and', 5),\n",
       " ('i', 6),\n",
       " ('a', 7),\n",
       " ('of', 8),\n",
       " ('in', 9),\n",
       " ('you', 10)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word2idx.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17d42675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx.get('town')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eede7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PADDING\n",
    "max_seq_length = min(max_seq_len, MAX_SEQUENCE_LENGTH)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen = max_seq_length, padding = 'post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen = max_seq_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcddffa3",
   "metadata": {},
   "source": [
    "# Pretrained Glove to use in the Embedding layer\n",
    "\n",
    "The embedding layer is created using the following steps:\n",
    "\n",
    "- First, the pretrain Glove for word embedding is loaded. This is just a mapping of word to a fixed length (of size embedding dimension) vector. \n",
    "\n",
    "- Next, an embedding matrix of size (num_words (or max_vocab_size), embedding_dim) is created. The embedding matrix only contains word vectors for those words found in the word2idx, which was created by calling tokenizer.word2idx. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a9fb612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load in pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('../glove.6B/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08e33b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,\n",
       " array([ 0.66258 ,  0.2123  ,  0.77968 , -0.29735 , -1.7562  , -0.25392 ,\n",
       "        -0.9175  , -0.12077 ,  0.082226, -1.4477  , -0.87622 , -0.61384 ,\n",
       "        -0.18897 , -0.92008 , -0.76244 ,  0.412   ,  0.50552 ,  0.23814 ,\n",
       "         0.69856 , -0.66039 ,  0.25735 , -0.21809 , -0.34929 ,  0.39163 ,\n",
       "         0.56563 , -0.14954 ,  0.5056  ,  0.79658 ,  1.5936  , -0.1479  ,\n",
       "         3.2168  ,  0.17621 ,  0.38781 , -0.23386 ,  0.27452 ,  0.94828 ,\n",
       "         0.27032 , -0.003935, -0.49437 ,  1.4444  , -0.78306 , -0.14778 ,\n",
       "         0.89745 , -0.20894 , -0.56203 ,  0.015886, -0.71619 , -0.99149 ,\n",
       "         0.79767 , -0.9672  ], dtype=float32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec.get('roads')), word2vec.get('roads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15eb2c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n",
      "There are 3000 words\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "print('There are %s words' %num_words)\n",
    "\n",
    "for word, i in word2idx.items():\n",
    "  if i < MAX_VOCAB_SIZE:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "232c1017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9eada4",
   "metadata": {},
   "source": [
    "# Neural network model with Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcdb7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained word embeddings into an Embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7614df80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 12, 50)       150000      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 12, 25),     7600        ['embedding[0][0]',              \n",
      "                                 (None, 25),                      'input_2[0][0]',                \n",
      "                                 (None, 25)]                      'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 12, 3000)     78000       ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 235,600\n",
      "Trainable params: 85,600\n",
      "Non-trainable params: 150,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create an LSTM network with a single LSTM\n",
    "\n",
    "#LSTM layer\n",
    "lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "\n",
    "#There are 3 inputs:\n",
    "#1. input state\n",
    "input_ = Input(shape=(max_seq_length,))\n",
    "#2. hidden state of LSTM\n",
    "initial_h = Input(shape=(LATENT_DIM,))\n",
    "#3. cell state of LSTM\n",
    "initial_c = Input(shape=(LATENT_DIM,))\n",
    "#Embedding layer\n",
    "x = embedding_layer(input_)\n",
    "x, _, _ = lstm(x, initial_state=[initial_h, initial_c])\n",
    "#Dense layer\n",
    "dense = Dense(num_words, activation='softmax')\n",
    "output = dense(x)\n",
    "\n",
    "model = Model([input_, initial_h, initial_c], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9471eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  # optimizer='rmsprop',\n",
    "  optimizer=Adam(learning_rate=0.01),\n",
    "  # optimizer=SGD(lr=0.01, momentum=0.9),\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c043f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot the targets (can't use sparse cross-entropy)\n",
    "one_hot_targets = np.zeros((len(input_sequences), max_seq_length, num_words))\n",
    "for i, target_sequence in enumerate(target_sequences):\n",
    "  for t, word in enumerate(target_sequence):\n",
    "    if word > 0:\n",
    "      one_hot_targets[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec212c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 4s 212ms/step - loss: 5.3906 - accuracy: 0.0224 - val_loss: 5.0641 - val_accuracy: 0.0229\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 4.6467 - accuracy: 0.0424 - val_loss: 4.8003 - val_accuracy: 0.0833\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 1s 127ms/step - loss: 4.4640 - accuracy: 0.0833 - val_loss: 4.8647 - val_accuracy: 0.0833\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 4.4378 - accuracy: 0.0833 - val_loss: 4.8948 - val_accuracy: 0.0833\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 4.4325 - accuracy: 0.0876 - val_loss: 4.8800 - val_accuracy: 0.0871\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 4.4033 - accuracy: 0.0866 - val_loss: 4.8349 - val_accuracy: 0.0833\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 4.3800 - accuracy: 0.0885 - val_loss: 4.8140 - val_accuracy: 0.0871\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 4.3642 - accuracy: 0.0912 - val_loss: 4.8088 - val_accuracy: 0.0871\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 4.3458 - accuracy: 0.0912 - val_loss: 4.8023 - val_accuracy: 0.0871\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 4.3216 - accuracy: 0.0912 - val_loss: 4.7987 - val_accuracy: 0.0871\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 4.2996 - accuracy: 0.0920 - val_loss: 4.7948 - val_accuracy: 0.0888\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 4.2805 - accuracy: 0.0925 - val_loss: 4.7874 - val_accuracy: 0.0880\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 4.2622 - accuracy: 0.0973 - val_loss: 4.7883 - val_accuracy: 0.0900\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 4.2424 - accuracy: 0.0977 - val_loss: 4.7792 - val_accuracy: 0.0906\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 4.2210 - accuracy: 0.0973 - val_loss: 4.7692 - val_accuracy: 0.0903\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 4.2032 - accuracy: 0.0994 - val_loss: 4.7677 - val_accuracy: 0.0909\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 4.1824 - accuracy: 0.0990 - val_loss: 4.7580 - val_accuracy: 0.0917\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 4.1632 - accuracy: 0.1009 - val_loss: 4.7538 - val_accuracy: 0.0909\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 4.1469 - accuracy: 0.0998 - val_loss: 4.7513 - val_accuracy: 0.0906\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 4.1272 - accuracy: 0.1012 - val_loss: 4.7478 - val_accuracy: 0.0894\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 1s 123ms/step - loss: 4.1083 - accuracy: 0.1022 - val_loss: 4.7452 - val_accuracy: 0.0897\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 4.0904 - accuracy: 0.1024 - val_loss: 4.7379 - val_accuracy: 0.0897\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 4.0746 - accuracy: 0.1026 - val_loss: 4.7441 - val_accuracy: 0.0900\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 4.0569 - accuracy: 0.1026 - val_loss: 4.7407 - val_accuracy: 0.0914\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 4.0421 - accuracy: 0.1036 - val_loss: 4.7378 - val_accuracy: 0.0894\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 4.0240 - accuracy: 0.1031 - val_loss: 4.7326 - val_accuracy: 0.0891\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 4.0086 - accuracy: 0.1034 - val_loss: 4.7305 - val_accuracy: 0.0894\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.9934 - accuracy: 0.1037 - val_loss: 4.7304 - val_accuracy: 0.0903\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 3.9774 - accuracy: 0.1045 - val_loss: 4.7311 - val_accuracy: 0.0903\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 3.9627 - accuracy: 0.1047 - val_loss: 4.7382 - val_accuracy: 0.0897\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 3.9520 - accuracy: 0.1044 - val_loss: 4.7328 - val_accuracy: 0.0911\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 3.9374 - accuracy: 0.1048 - val_loss: 4.7318 - val_accuracy: 0.0888\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 3.9202 - accuracy: 0.1063 - val_loss: 4.7268 - val_accuracy: 0.0914\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 3.9051 - accuracy: 0.1078 - val_loss: 4.7266 - val_accuracy: 0.0906\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 3.8961 - accuracy: 0.1071 - val_loss: 4.7260 - val_accuracy: 0.0903\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 3.8835 - accuracy: 0.1071 - val_loss: 4.7311 - val_accuracy: 0.0935\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 3.8673 - accuracy: 0.1091 - val_loss: 4.7284 - val_accuracy: 0.0911\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 1s 127ms/step - loss: 3.8553 - accuracy: 0.1083 - val_loss: 4.7312 - val_accuracy: 0.0917\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 3.8435 - accuracy: 0.1090 - val_loss: 4.7325 - val_accuracy: 0.0943\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 3.8310 - accuracy: 0.1090 - val_loss: 4.7336 - val_accuracy: 0.0917\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 1s 128ms/step - loss: 3.8174 - accuracy: 0.1091 - val_loss: 4.7341 - val_accuracy: 0.0923\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.8061 - accuracy: 0.1098 - val_loss: 4.7342 - val_accuracy: 0.0920\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 3.7968 - accuracy: 0.1108 - val_loss: 4.7328 - val_accuracy: 0.0938\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 3.7855 - accuracy: 0.1114 - val_loss: 4.7358 - val_accuracy: 0.0923\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 3.7766 - accuracy: 0.1114 - val_loss: 4.7376 - val_accuracy: 0.0938\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 3.7639 - accuracy: 0.1119 - val_loss: 4.7351 - val_accuracy: 0.0955\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 3.7524 - accuracy: 0.1119 - val_loss: 4.7419 - val_accuracy: 0.0938\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 3.7434 - accuracy: 0.1122 - val_loss: 4.7454 - val_accuracy: 0.0961\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 3.7313 - accuracy: 0.1129 - val_loss: 4.7489 - val_accuracy: 0.0935\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 3.7215 - accuracy: 0.1130 - val_loss: 4.7478 - val_accuracy: 0.0969\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 3.7115 - accuracy: 0.1132 - val_loss: 4.7490 - val_accuracy: 0.0949\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 3.7003 - accuracy: 0.1140 - val_loss: 4.7487 - val_accuracy: 0.0969\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 3.6902 - accuracy: 0.1148 - val_loss: 4.7520 - val_accuracy: 0.0969\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 3.6813 - accuracy: 0.1151 - val_loss: 4.7557 - val_accuracy: 0.0978\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 3.6706 - accuracy: 0.1152 - val_loss: 4.7591 - val_accuracy: 0.0978\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.6628 - accuracy: 0.1153 - val_loss: 4.7575 - val_accuracy: 0.0978\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 3.6514 - accuracy: 0.1154 - val_loss: 4.7595 - val_accuracy: 0.0984\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 3.6448 - accuracy: 0.1154 - val_loss: 4.7661 - val_accuracy: 0.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 3.6351 - accuracy: 0.1161 - val_loss: 4.7735 - val_accuracy: 0.0969\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 3.6244 - accuracy: 0.1161 - val_loss: 4.7681 - val_accuracy: 0.0978\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 3.6167 - accuracy: 0.1172 - val_loss: 4.7754 - val_accuracy: 0.0990\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 3.6074 - accuracy: 0.1165 - val_loss: 4.7716 - val_accuracy: 0.0981\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 3.5981 - accuracy: 0.1167 - val_loss: 4.7802 - val_accuracy: 0.0987\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 3.5889 - accuracy: 0.1172 - val_loss: 4.7847 - val_accuracy: 0.0998\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 1s 133ms/step - loss: 3.5819 - accuracy: 0.1176 - val_loss: 4.7747 - val_accuracy: 0.0992\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 3.5728 - accuracy: 0.1173 - val_loss: 4.7870 - val_accuracy: 0.0969\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 3.5636 - accuracy: 0.1182 - val_loss: 4.7892 - val_accuracy: 0.0992\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.5573 - accuracy: 0.1180 - val_loss: 4.7954 - val_accuracy: 0.0990\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 3.5467 - accuracy: 0.1185 - val_loss: 4.7903 - val_accuracy: 0.0981\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 3.5416 - accuracy: 0.1177 - val_loss: 4.8004 - val_accuracy: 0.0992\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.5318 - accuracy: 0.1185 - val_loss: 4.8043 - val_accuracy: 0.0975\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 3.5237 - accuracy: 0.1182 - val_loss: 4.8037 - val_accuracy: 0.0984\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 3.5161 - accuracy: 0.1187 - val_loss: 4.8053 - val_accuracy: 0.0978\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 1s 155ms/step - loss: 3.5101 - accuracy: 0.1185 - val_loss: 4.8178 - val_accuracy: 0.0990\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 3.5023 - accuracy: 0.1200 - val_loss: 4.8165 - val_accuracy: 0.0975\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 3.4931 - accuracy: 0.1188 - val_loss: 4.8151 - val_accuracy: 0.0972\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 3.4866 - accuracy: 0.1190 - val_loss: 4.8215 - val_accuracy: 0.0969\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 3.4782 - accuracy: 0.1196 - val_loss: 4.8229 - val_accuracy: 0.0978\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 3.4724 - accuracy: 0.1191 - val_loss: 4.8272 - val_accuracy: 0.0972\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 3.4641 - accuracy: 0.1197 - val_loss: 4.8383 - val_accuracy: 0.0969\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.4555 - accuracy: 0.1193 - val_loss: 4.8390 - val_accuracy: 0.0964\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.4514 - accuracy: 0.1196 - val_loss: 4.8395 - val_accuracy: 0.0972\n",
      "Epoch 83/200\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 3.4415 - accuracy: 0.1207 - val_loss: 4.8372 - val_accuracy: 0.0972\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 3.4367 - accuracy: 0.1204 - val_loss: 4.8423 - val_accuracy: 0.0969\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 3.4319 - accuracy: 0.1196 - val_loss: 4.8511 - val_accuracy: 0.0966\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.4202 - accuracy: 0.1203 - val_loss: 4.8482 - val_accuracy: 0.0966\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 3.4128 - accuracy: 0.1211 - val_loss: 4.8566 - val_accuracy: 0.0966\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 3.4086 - accuracy: 0.1214 - val_loss: 4.8592 - val_accuracy: 0.0958\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 3.4015 - accuracy: 0.1219 - val_loss: 4.8668 - val_accuracy: 0.0966\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 3.3940 - accuracy: 0.1222 - val_loss: 4.8697 - val_accuracy: 0.0958\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 3.3857 - accuracy: 0.1215 - val_loss: 4.8649 - val_accuracy: 0.0958\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.3831 - accuracy: 0.1220 - val_loss: 4.8784 - val_accuracy: 0.0961\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 3.3741 - accuracy: 0.1223 - val_loss: 4.8804 - val_accuracy: 0.0961\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 3.3708 - accuracy: 0.1225 - val_loss: 4.8835 - val_accuracy: 0.0961\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 3.3595 - accuracy: 0.1230 - val_loss: 4.8832 - val_accuracy: 0.0964\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 3.3553 - accuracy: 0.1227 - val_loss: 4.8882 - val_accuracy: 0.0955\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 3.3487 - accuracy: 0.1237 - val_loss: 4.8933 - val_accuracy: 0.0952\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 3.3397 - accuracy: 0.1238 - val_loss: 4.8987 - val_accuracy: 0.0949\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 3.3337 - accuracy: 0.1238 - val_loss: 4.9057 - val_accuracy: 0.0955\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.3279 - accuracy: 0.1242 - val_loss: 4.9036 - val_accuracy: 0.0952\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 3.3220 - accuracy: 0.1251 - val_loss: 4.9082 - val_accuracy: 0.0952\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 3.3149 - accuracy: 0.1250 - val_loss: 4.9082 - val_accuracy: 0.0961\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 3.3111 - accuracy: 0.1259 - val_loss: 4.9169 - val_accuracy: 0.0961\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 3.3024 - accuracy: 0.1261 - val_loss: 4.9234 - val_accuracy: 0.0949\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 3.2959 - accuracy: 0.1257 - val_loss: 4.9256 - val_accuracy: 0.0955\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 3.2940 - accuracy: 0.1263 - val_loss: 4.9256 - val_accuracy: 0.0955\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 3.2863 - accuracy: 0.1275 - val_loss: 4.9327 - val_accuracy: 0.0952\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.2802 - accuracy: 0.1267 - val_loss: 4.9433 - val_accuracy: 0.0943\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 3.2728 - accuracy: 0.1290 - val_loss: 4.9468 - val_accuracy: 0.0943\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 3.2672 - accuracy: 0.1278 - val_loss: 4.9409 - val_accuracy: 0.0958\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 1s 150ms/step - loss: 3.2603 - accuracy: 0.1280 - val_loss: 4.9474 - val_accuracy: 0.0958\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 3.2557 - accuracy: 0.1285 - val_loss: 4.9591 - val_accuracy: 0.0946\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 3.2532 - accuracy: 0.1296 - val_loss: 4.9621 - val_accuracy: 0.0940\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 3.2452 - accuracy: 0.1290 - val_loss: 4.9613 - val_accuracy: 0.0938\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.2396 - accuracy: 0.1291 - val_loss: 4.9672 - val_accuracy: 0.0940\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - loss: 3.2349 - accuracy: 0.1292 - val_loss: 4.9702 - val_accuracy: 0.0940\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 2s 191ms/step - loss: 3.2282 - accuracy: 0.1302 - val_loss: 4.9780 - val_accuracy: 0.0943\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.2232 - accuracy: 0.1302 - val_loss: 4.9804 - val_accuracy: 0.0935\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.2174 - accuracy: 0.1295 - val_loss: 4.9801 - val_accuracy: 0.0935\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 1s 136ms/step - loss: 3.2119 - accuracy: 0.1307 - val_loss: 4.9852 - val_accuracy: 0.0943\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 3.2099 - accuracy: 0.1302 - val_loss: 5.0021 - val_accuracy: 0.0938\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 3.2030 - accuracy: 0.1316 - val_loss: 4.9954 - val_accuracy: 0.0935\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.1965 - accuracy: 0.1311 - val_loss: 5.0038 - val_accuracy: 0.0940\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 1s 135ms/step - loss: 3.1944 - accuracy: 0.1315 - val_loss: 5.0021 - val_accuracy: 0.0946\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 3.1891 - accuracy: 0.1327 - val_loss: 5.0038 - val_accuracy: 0.0938\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.1854 - accuracy: 0.1326 - val_loss: 5.0205 - val_accuracy: 0.0935\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.1803 - accuracy: 0.1313 - val_loss: 5.0268 - val_accuracy: 0.0929\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 3.1753 - accuracy: 0.1323 - val_loss: 5.0345 - val_accuracy: 0.0938\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 3.1748 - accuracy: 0.1333 - val_loss: 5.0438 - val_accuracy: 0.0940\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 3.1668 - accuracy: 0.1324 - val_loss: 5.0427 - val_accuracy: 0.0940\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 3.1655 - accuracy: 0.1330 - val_loss: 5.0385 - val_accuracy: 0.0935\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 3.1535 - accuracy: 0.1328 - val_loss: 5.0400 - val_accuracy: 0.0932\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 3.1511 - accuracy: 0.1346 - val_loss: 5.0374 - val_accuracy: 0.0943\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 3.1473 - accuracy: 0.1327 - val_loss: 5.0584 - val_accuracy: 0.0935\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 3.1414 - accuracy: 0.1351 - val_loss: 5.0540 - val_accuracy: 0.0935\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 3.1375 - accuracy: 0.1349 - val_loss: 5.0599 - val_accuracy: 0.0929\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 3.1348 - accuracy: 0.1353 - val_loss: 5.0794 - val_accuracy: 0.0929\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 3.1317 - accuracy: 0.1345 - val_loss: 5.0753 - val_accuracy: 0.0943\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 3.1240 - accuracy: 0.1359 - val_loss: 5.0560 - val_accuracy: 0.0929\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 3.1252 - accuracy: 0.1358 - val_loss: 5.0762 - val_accuracy: 0.0932\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.1225 - accuracy: 0.1353 - val_loss: 5.0708 - val_accuracy: 0.0938\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 3.1168 - accuracy: 0.1352 - val_loss: 5.0879 - val_accuracy: 0.0938\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.1113 - accuracy: 0.1369 - val_loss: 5.0937 - val_accuracy: 0.0935\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 3.1082 - accuracy: 0.1370 - val_loss: 5.1062 - val_accuracy: 0.0935\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 3.1020 - accuracy: 0.1366 - val_loss: 5.0952 - val_accuracy: 0.0938\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 1s 137ms/step - loss: 3.1005 - accuracy: 0.1375 - val_loss: 5.1087 - val_accuracy: 0.0940\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 3.0980 - accuracy: 0.1370 - val_loss: 5.1064 - val_accuracy: 0.0935\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 3.0903 - accuracy: 0.1377 - val_loss: 5.1264 - val_accuracy: 0.0935\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 3.0878 - accuracy: 0.1380 - val_loss: 5.1310 - val_accuracy: 0.0935\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 3.0849 - accuracy: 0.1373 - val_loss: 5.1027 - val_accuracy: 0.0923\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 3.0840 - accuracy: 0.1384 - val_loss: 5.1231 - val_accuracy: 0.0943\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 3.0791 - accuracy: 0.1392 - val_loss: 5.1257 - val_accuracy: 0.0929\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 3.0789 - accuracy: 0.1397 - val_loss: 5.1252 - val_accuracy: 0.0932\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 3.0710 - accuracy: 0.1394 - val_loss: 5.1607 - val_accuracy: 0.0929\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 3.0685 - accuracy: 0.1413 - val_loss: 5.1511 - val_accuracy: 0.0935\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 3.0642 - accuracy: 0.1391 - val_loss: 5.1536 - val_accuracy: 0.0932\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 3.0612 - accuracy: 0.1406 - val_loss: 5.1553 - val_accuracy: 0.0940\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 3.0570 - accuracy: 0.1400 - val_loss: 5.1652 - val_accuracy: 0.0914\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.0563 - accuracy: 0.1425 - val_loss: 5.1533 - val_accuracy: 0.0935\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 3.0523 - accuracy: 0.1410 - val_loss: 5.1715 - val_accuracy: 0.0920\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.0488 - accuracy: 0.1420 - val_loss: 5.1830 - val_accuracy: 0.0935\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 1s 140ms/step - loss: 3.0451 - accuracy: 0.1420 - val_loss: 5.1835 - val_accuracy: 0.0926\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.0414 - accuracy: 0.1413 - val_loss: 5.1793 - val_accuracy: 0.0943\n",
      "Epoch 164/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 3.0395 - accuracy: 0.1426 - val_loss: 5.2018 - val_accuracy: 0.0914\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 3.0394 - accuracy: 0.1434 - val_loss: 5.2112 - val_accuracy: 0.0929\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 3.0337 - accuracy: 0.1419 - val_loss: 5.1973 - val_accuracy: 0.0938\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 3.0324 - accuracy: 0.1432 - val_loss: 5.2035 - val_accuracy: 0.0917\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 2s 182ms/step - loss: 3.0286 - accuracy: 0.1434 - val_loss: 5.2099 - val_accuracy: 0.0923\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 1s 156ms/step - loss: 3.0263 - accuracy: 0.1441 - val_loss: 5.2105 - val_accuracy: 0.0920\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 3.0223 - accuracy: 0.1445 - val_loss: 5.2200 - val_accuracy: 0.0920\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 1s 159ms/step - loss: 3.0187 - accuracy: 0.1449 - val_loss: 5.2195 - val_accuracy: 0.0932\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 3.0163 - accuracy: 0.1451 - val_loss: 5.2349 - val_accuracy: 0.0923\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 149ms/step - loss: 3.0140 - accuracy: 0.1453 - val_loss: 5.2318 - val_accuracy: 0.0920\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 3.0100 - accuracy: 0.1453 - val_loss: 5.2410 - val_accuracy: 0.0911\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 3.0059 - accuracy: 0.1466 - val_loss: 5.2389 - val_accuracy: 0.0920\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 3.0066 - accuracy: 0.1450 - val_loss: 5.2532 - val_accuracy: 0.0920\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 3.0058 - accuracy: 0.1470 - val_loss: 5.2510 - val_accuracy: 0.0923\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 1s 152ms/step - loss: 3.0013 - accuracy: 0.1466 - val_loss: 5.2684 - val_accuracy: 0.0923\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 2.9989 - accuracy: 0.1473 - val_loss: 5.2527 - val_accuracy: 0.0920\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 2.9967 - accuracy: 0.1478 - val_loss: 5.2781 - val_accuracy: 0.0926\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 2.9916 - accuracy: 0.1461 - val_loss: 5.2710 - val_accuracy: 0.0926\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 2.9917 - accuracy: 0.1475 - val_loss: 5.2779 - val_accuracy: 0.0923\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 2.9874 - accuracy: 0.1484 - val_loss: 5.2653 - val_accuracy: 0.0923\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 2.9875 - accuracy: 0.1490 - val_loss: 5.2723 - val_accuracy: 0.0932\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 2.9832 - accuracy: 0.1494 - val_loss: 5.3114 - val_accuracy: 0.0923\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 2.9800 - accuracy: 0.1492 - val_loss: 5.2976 - val_accuracy: 0.0926\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 2.9781 - accuracy: 0.1483 - val_loss: 5.3042 - val_accuracy: 0.0920\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 1s 161ms/step - loss: 2.9749 - accuracy: 0.1500 - val_loss: 5.2894 - val_accuracy: 0.0926\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 2.9750 - accuracy: 0.1502 - val_loss: 5.3089 - val_accuracy: 0.0926\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 2.9691 - accuracy: 0.1496 - val_loss: 5.3160 - val_accuracy: 0.0914\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 1s 154ms/step - loss: 2.9679 - accuracy: 0.1506 - val_loss: 5.3258 - val_accuracy: 0.0923\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 1s 158ms/step - loss: 2.9678 - accuracy: 0.1500 - val_loss: 5.3339 - val_accuracy: 0.0914\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 2.9638 - accuracy: 0.1506 - val_loss: 5.3176 - val_accuracy: 0.0926\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 2.9645 - accuracy: 0.1507 - val_loss: 5.3286 - val_accuracy: 0.0923\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 2.9571 - accuracy: 0.1508 - val_loss: 5.3492 - val_accuracy: 0.0920\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 2.9609 - accuracy: 0.1523 - val_loss: 5.3365 - val_accuracy: 0.0914\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 2.9537 - accuracy: 0.1508 - val_loss: 5.3438 - val_accuracy: 0.0917\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 2.9527 - accuracy: 0.1508 - val_loss: 5.3527 - val_accuracy: 0.0926\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 1s 147ms/step - loss: 2.9540 - accuracy: 0.1519 - val_loss: 5.3634 - val_accuracy: 0.0917\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 2.9480 - accuracy: 0.1510 - val_loss: 5.3770 - val_accuracy: 0.0914\n"
     ]
    }
   ],
   "source": [
    "#use zeros for initial states h and c\n",
    "z = np.zeros((len(input_sequences), LATENT_DIM))\n",
    "\n",
    "r = model.fit(\n",
    "  [input_sequences, z, z],\n",
    "  one_hot_targets,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=VALIDATION_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17235e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA2s0lEQVR4nO3deXxU1f3/8ddnJhsBQhJICARCWCJ7WAyrgiIugAtIscW9tpVasYp1rdqq39a2Lu1PrRaKiltVXBDFDRQVcWFLZA37TgiEhCUkkG1mzu+PMwlDSMggSSYZPs/HgweZu82Zm8n7nnvOufeKMQallFLByxHoAiillKpbGvRKKRXkNOiVUirIadArpVSQ06BXSqkgFxLoAlSlVatWJjk5OdDFUEqpRiMjIyPPGBNX1bwGGfTJycmkp6cHuhhKKdVoiMiO6uZp041SSgU5DXqllApyGvRKKRXkGmQbfVXKysrIysqiuLg40EVpkCIiImjXrh2hoaGBLopSqoFpNEGflZVF8+bNSU5ORkQCXZwGxRjD/v37ycrKomPHjoEujlKqgWk0TTfFxcW0bNlSQ74KIkLLli31bEcpVaVGE/SAhvxJ6L5RSlWnUQW9Uko1dquyDrFk6/56fU8NeqWUqic5h4u57sUl3DBjKdvyjgCwNvswI/+5gNcXV3u902nToFdKqTrm8RjyCkt4cPZqSlwewkIc3PveSr5ev48bZixlx/6j/OmDNTz/9Wbq4mFQGvSnYNy4cZx99tn07NmT6dOnAzB37lz69+9Pnz59GDlyJACFhYXcdNNN9O7dm9TUVGbNmhXIYiul6pAxhu15R1i+8yDGGOZl7uVnU3/g41XZvPrDdkY8tYBuf5pL2l/nM3/dPu6+uCt/vqwHy7Yf5KZXluExhk9uH8a4vm2ZlZHFkVJ3rZex0Qyv9PXoR5mszT5cq9vs0TaKhy/vedJlZsyYQWxsLEVFRQwYMICxY8dy8803s3DhQjp27MiBAwcA+Mtf/kKLFi1YvXo1AAcPHqzVsiqlAsPjMZS6PUSEOgEoKnUzYdoPZHrzKLVdC9bszicsxMFtby4HYGByLBf3bE2bqAg6xjVjeEorALrEN6O4zEO3hObENA3jXz/vy8GjpTQLr/1YbpRBHyjPPvsss2fPBmDXrl1Mnz6d4cOHV4xdj42NBWD+/PnMnDmzYr2YmJj6L6xSqtYcLi7jxW+3MSsji+z8IlLim/H7C1LYmFNAZvZhHhjTjVCng2e/3MQ5XVrx/LX9WbAhl+bhIZzfNa7KUXH9ko7PBYdDaNksvE7K3yiDvqaad11YsGAB8+fPZ9GiRURGRnL++efTp08fNmzYcMKyxhgd7qhUkJiXuZcH3l/NgaOlDEuJY3z/RL5av4/fv7WcEIcwrm9bJg3vDMB1gzsQ4hBEhCv6tA1wyY/RNno/5efnExMTQ2RkJOvXr2fx4sWUlJTwzTffsG3bNoCKppuLL76Y5557rmJdbbpRqnFYsesQj8zJZG++vfjwnWW7+N3/Mmgb3YQ5k8/ltV8N5K6Lu/L+rUMZ3z+RmKZhPDCme8X6oU5Hg6zkNcoafSCMGjWKadOmkZqaSteuXRk8eDBxcXFMnz6d8ePH4/F4iI+P54svvuChhx5i8uTJ9OrVC6fTycMPP8z48eMD/RGUUpWszsrnUFEpvdq24KEP1/DJqj0A7D5UxDWDkrh31iqGpbTiv9efTWTYsbgMD3Hyr5/3xe0xOB0NL9gr06D3U3h4OJ999lmV80aPHn3c62bNmvHqq6/WR7GUUqfAGMMT8zaQFBvJ5X3acuPLSzlwpJRQp2AMTLkwBY+BZ7/cxA+b8+iW0JwXbkir6HytrDGEPGjQK6XOIP9ZsIWpC7YQ4hCWbN3PgSOl3H3xWezYf5TrBnegT/toSl0ePl6VTfahIv59db9qQ74x0aBXSgWlolI3X2/Yx1fr97Fi1yEOF5Wxr6CE0b0SWLb9IB+syGZkt3huuyDluPXCQhy8+ZvBHCoqJaV18wCVvnZp0CulgkZxmZsFG/bx8ao9fLluH0VlbmIiQ+mfFEN8VDgtm4Zz2wVd+G5THg9+sJq7Lu5a5XYSWkSQ0CKinktfdzTolVJB4Yu1Odw3axUHjpTSsmkY4/sncllqWwZ2jD2hLf3CHq0Z2T2+QY6QqQsa9EqpRmXRlv385eO13DOqK0M6teTRjzL5ccchNuQU0LNtFM9O7MfgTrGEOE8+evxMCXnQoFdKNSD5R8t45Yft3Dy843HDGcu9s2wXf5y9GrfHcPc7KxnSuSUfr9rDyG7xXNG3Lb8Z1pHwkMbfeVrbNOiVUg3Gyz9s4+n5mzh4tJQJZ7fjkTmZFJa4SG3XgtG92/DA7NUM7dySKReexdUvLObjVXuYPKIz91zSLdBFb9D8ujJWREaJyAYR2Swi91cxv5uILBKREhG5u4r5ThFZLiIf10ahG4NmzZoFughKNVjr9hzmwdmrKXV5Kqa5PYZ3lu0i1Cm88sN2rn5hMbsOHiUxugmzftzNTS8vo210E567pj9nd4jhiZ+lct3gJP5wUdUdquqYGmv0IuIEngcuArKAZSIyxxiz1mexA8DtwLhqNnMHsA6IOq3SKqUaPWMMf/pgDek7DtI/KYY+7Vvw32+20jWhOdn5xTw5IZV/f7UZl9vD278dQvvYSJbvPMjzX2/hDxedRYsmoQCM65fIuH6JAf40jYM/TTcDgc3GmK0AIjITGAtUBL0xZh+wT0QurbyyiLQDLgUeA/5QG4Xms/th7+pa2VSFhN4w+h/Vzr7vvvvo0KEDt956KwCPPPIIIsLChQs5ePAgZWVl/PWvf2Xs2LE1vlVhYSFjx46tcr3XXnuNp556ChEhNTWV119/nZycHG655Ra2bt0KwNSpUxk6dGgtfGil6k9BcRnb8o6QfaiY9B0HCQ9x8N+FWwh1Oipu89uyaRhj+yZycY8EHA5oHmFDvV9SDC/emBbI4jdq/gR9IrDL53UWMOgU3uNp4F7gpFceiMgkYBJAUlLSKWy+fkycOJEpU6ZUBP0777zD3LlzufPOO4mKiiIvL4/BgwdzxRVX1NibHxERwezZs09Yb+3atTz22GN8//33tGrVquImabfffjvnnXces2fPxu12U1hYWOefV6na4vYYXvh2K1MXbCG/qAyA5JaR3Hp+F+6dtQqAv4/vTWZ2Pn3aRRMW4iAsRO+3WJv8CfqqUsuvZ12JyGXAPmNMhoicf7JljTHTgekAaWlpJ9/+SWredaVfv37s27eP7OxscnNziYmJoU2bNtx5550sXLgQh8PB7t27ycnJISEh4aTbMsbwwAMPnLDeV199xYQJE2jVyj6YoPz+9l999RWvvfYaAE6nkxYtWtTth1Wqlhw6WsrtM1ewcGMuF3SL59LebViZdYjLUtvSLymaF7/bSu/EaK4e2PAqd8HEn6DPAtr7vG4HZPu5/XOAK0RkDBABRInI/4wx151aMRuGCRMm8N5777F3714mTpzIG2+8QW5uLhkZGYSGhpKcnExxcXGN26luPb2PvWrMjDEs3JTHF2v3EuJwcPPwTvz29XQ27i3kH+N7M9Eb5j87u13FOp/cPoyQRnJjsMbMn6BfBqSISEdgNzARuMafjRtj/gj8EcBbo7+7sYY82Oabm2++mby8PL755hveeecd4uPjCQ0N5euvv2bHDv+e4p6fn1/leiNHjuTKK6/kzjvvpGXLlhw4cIDY2FhGjhzJ1KlTmTJlCm63myNHjhAVpf3aqv65PYbsQ0WUuNx0atWMr9bv408frmFI55bsLyzlm425RIY5KXV5eH3xDgSYfsPZXNCtdZXbC63hoiZVO2oMemOMS0RuA+YBTmCGMSZTRG7xzp8mIglAOnZUjUdEpgA9jDG1+2DXAOvZsycFBQUkJibSpk0brr32Wi6//HLS0tLo27cv3br5N5a3uvV69uzJgw8+yHnnnYfT6aRfv3688sorPPPMM0yaNImXXnoJp9PJ1KlTGTJkSF1+VKVO4PYYrnlhMUu22b6jNi0iyDlcTIeWTZm7Zi8AD1/eg2sGJbF+TwGPfbKO64d0qDbkVf0RY/xqbq9XaWlpJj09/bhp69ato3v37tWsoUD3kao9c9fsZcPeAtpER3BZahsiw0J4c8lOHpi9mskjOpMUG8m8zBzim4fz58t74DG26aZ8lIyqfyKSYYypcmiSXhmr1Blsze58QpyCIHy4YjcDOtoBALf8L6NimSfmrueCbvHMy8xhcKdY7r64KyLCLwZoB2pjoUFfh1avXs31119/3LTw8HCWLFkSoBKpM53HY3gvI4vzu8VR5jaMff573B6fs/oFW2ga5qRbQnNm/W4o6/Yc5vmvN7NwYx7hIQ7+MraXDhhohBpV0De2USm9e/dmxYoV9fJeDbEJTjU8H67czb2zVnFh99ac1boZxhj+Mq4XbreHS3ol8PQXm5i3di//vrofTcNDSEuO5eWbBga62Oo0NZqgj4iIYP/+/bRs2bJRhX19MMawf/9+IiKC50EJ6vTkFZbw3FebuX5IBzrHNaOguAyPgX98tp6wEAfz1+Xww5Y8LuzemusHd6hY7/EJqfzN07vRPAtV+afRBH27du3IysoiNzc30EVpkCIiImjXrl3NC6qgsuvAUZ77ajMOB4zu1YbhZ8Wxv7CEa15YzMacQuastI/Lm/VjFuUtNK//eiB3vr2SvMISbhiSfMI2NeSDT6MJ+tDQUDp27BjoYijVYBwpcXHza+ls33+EMKeDWT/u5sUb0vjbp+vYsf8oT/wslWe+3MT7y3dz9cAkoiNDSYiKYFhKHP83tifzMvdyTpeWgf4Yqh40muGVSp3pjpa6mDB1EeGhDq7sl8iHK7JZvvMgr/5qID3btuDSZ79lT34x4SEOXrpxAOemtOLgkVIKS1y0j40MdPFVHdPhlUo1UsYYXlu0g9ZREXy7KZd1ew/TunkEf/4wk9ZR4Tz+s1SGpcQB8J9r+/PA7DX8cXQ3zk2x90uKaRpGTNOwQH4E1QBo0CvVgLy5ZCev/LCNgmIXV/RpS5MwJ0/P31Qx/+ZhHbnnkm5syS3krNbNj2tP75cUw2d3DAtEsVUDp0GvVB2qakiwx2N45KNM1u05zN0Xd6V1VAR78ov5ZmMu077ZQt/20STFRvLfhfb5A+P6tmVYShyrsg5x18VdCQtx0L2N3utI+U+DXqk6dMv/MihzG/57/dmEOh24PYa/fbqO1xbtoHlECL+Yvvi45cf3S+SJCamEOB18sTaHJVv3c8+oroSHOI+766NSp0KDXqk6kpmdz7zMHADun7Wa5JaRvJuRxc4DR/nl0GTuHdWVOSuyCXU6SGgRQdvoJiS3jKw4A7ioR2su6qE3BFOnT4NeqVrk9hj+9OEaYiJD2ZNfTJNQJ+P7J/LGkp0ADEyO5f7R3RjdKwERqbhHu1J1SYNeqVr01OcbeNMb6gDXDU7i0St6MapXAt0SoohrHh7A0qkzlQa9Uj/Rt5tyWbbtAEVlbi5LbcvczL1MXbCFqwcm0bV1M178bhu/PrcTTodUDIFUKhA06JU6BaUuDwAvfbeNx+euxyEQ4nDwwrfbALjq7HY8ekVPwkIc/PIcvZJbNQwa9Er56fvNedz6xo/kF5UBcHmftjw5IZXiMjcfrdpD57imDO3cKsClVOpEGvRKVcHjMeQUFLO/sJTiMjfzMvfy8vfb6RzXjN+c25HoyFCuGdQBp0OICHUedwdIpRoaDXqlKlm67QC/+18G+4+UVkwLcQije7fhsSt7EaWPy1ONjAa9OuPtPlTEa4u2MytjN13im7J85yESY5ow5aKziG8ejlOEfknRtGymI2ZU46RBr4Ke22P4fnMeH67IpmOrSH57XmeyDhYxc9lOPlqRTXZ+MSIwsls8WQeLSEuO4dmJ/TTYVdDwK+hFZBTwDOAEXjTG/KPS/G7Ay0B/4EFjzFPe6e2B14AEwANMN8Y8U3vFV6p6uw4c5d2MLGZlZLH7UBHNwkMoLHHx+uId5BwuwekQRnSNY9LwTgw/K45Occ0CXWSl6kSNQS8iTuB54CIgC1gmInOMMWt9FjsA3A6Mq7S6C7jLGPOjiDQHMkTki0rrKvWT7TpwlKXbDnBOl1YktLCPUnS5PTw+dz0vfmeHPA5LieOBMd25sEc8X6zN4Y3FO7lhSDITzm5H6yh9/KIKfv7U6AcCm40xWwFEZCYwFqgIa2PMPmCfiFzqu6IxZg+wx/tzgYisAxJ911XKV9bBozgdQpsWTWpcNq+whGteXMyuA0UAXD0wiV+f25GHPljN4q0HuGZQEpNHdCEx+ti2Lktty2Wpbeus/Eo1RP4EfSKwy+d1FjDoVN9IRJKBfsCSauZPAiYBJCXp/T/ORAeOlDLu+e8xBmbfeg5JLSNZszuft5ftYlCnWErKPLz8wzbOat2c7glRzPoxi9yCEv5zbX/Stx9kxvfbeGvpTpqGOXnqqj5M0Ls9KgX4F/RVPSn4lJ4/KCLNgFnAFGPM4aqWMcZMB6aDfZTgqWxfNQ6FJS4iQ504fB6WYYxhxa5DlLo8/G/JTg4dLSMyzMm1Ly0mKTaSH7bsR4DXF+8AICW+GV9k5vD+j7tJjG7C89f0Z2T31ozp3YZBnWL5ev0+bh+ZQtvoms8IlDpT+BP0WUB7n9ftgGx/30BEQrEh/4Yx5v1TK55qzMrcHl79YTslLg+5BSW8uXQnZyfFcPvIFB76YDUFxS6imoSyeV9hxTpTLkxhaOdW3P/+KgqKXUwa3onfndeZ5TsPUer2cFH31pS6PRSWuGhVaVTMJT0TuKRnQn1/TKUavBofDi4iIcBGYCSwG1gGXGOMyaxi2UeAQp9RNwK8Chwwxkzxt1D6cPDGoaC4jOY+Fw+Vujx8vWEf89fmkBQbyZJtB/hucx4ATocwsls8X2/YR5nb0KZFBAM7xpJzuJjL+7QlISqC7PxiJg5oT6jTEaiPpFSjdVoPBzfGuETkNmAednjlDGNMpojc4p0/TUQSgHQgCvCIyBSgB5AKXA+sFpEV3k0+YIz59DQ/kwqwWRlZ3P3eSsb1TeSOkSmsyc7nyXkb2LH/KM0jQigodhHiEJ6ckMro3m0oc3mIaRrG4q37+WhlNndedNYJNXKlVN2osUYfCFqjb5jyi8p4N30XeYWlvPDtVpJbRrIt7wge71eoS3wz7hvVjRFd4zh4tAy3x1QMeVRK1a3TqtGrM48xhoISF4eOlHGoqJRDR8vIOVzM0/M3sfuQHco4MDmWGTcNYGtuISuz8unYsimDOsVWNLvoAzaUajg06BUAh46W8soP25mzMpsd+4/i9px4ppcUG8ms3w0ltV0LQhyCiJDaLprUdtH1X2CllN806BXLdx7ktjeXk51fxOCOLRnVM4GYyDCiI0OJjgwjJjKU6MhQkmKbEhaiHaVKNTYa9GcwYwwvf7+dv3+2jtZREXxw6zn0aR8d6GIppWqZBv0ZZlXWIWZlZLFubwHr9xzmcLGLC7u35p9X9aFFpN5nXalgpEF/Biguc7NhbwGzl+/mtUXbiQh10r1NFFf0bcuA5Fiu6NMWe8mDUioYadAHGY/HsHT7AZwOYdGW/bz6w/aKJyWJ2Bt/3T+6mz4lSakziAZ9EFmVdYgHZ69h9e78imkju8XTv0MM7WKaMCwljtimYQEsoVIqEDTog8TSbQe4ccZSWjQJ5ckJqSS0iCC+eQRdE5oHumhKqQDToA8Cc9fs4a53VtI2OoK3Jg0mvrlejaqUOkaDvpH4x2friW8eznWDOzB94RZW786nuMzD4eIylu88RGq7Frx4Q5qGvFLqBBr0jcAPm/OY9s0WAP6zYDN5haV0jmtK0/AQIkKc3DEyhckjuujFTEqpKmnQN0DfbsrlnfQs7r2kK+1imvDPLzaSEBXB9UM68PayXUy9theje7cJdDGVUo2EBn0Ds7+whCkzV7D/SCkLNuyjZ9soMnYc5C/jenH94A5MHtEl0EVUSjUyeq7fgBhjeOiDNRQUu3jpxjQGJsdSXObh6oFJ/CKtfc0bUEqpKmiNvgGZszKbz9bs5b5R3RjZvTUju7cOdJGUUkFAa/QBZIyh/MEve/OL+fOHmfRLimbS8E4BLplSKphojT4A9uQX8dgn61iy7QDFZW76J8WQvv0ALo/hqav64HTofWeUUrVHg74Oudwevt2Ux6BOsUSGhbAt7whLt+3nyXkbKCp1c0nPBEKcwrLtB7mkZwI3D+9E57hmgS62UirIaNDXEZfbwx1vr+CTVXto1SyMVs3CWb+3AIBOcU156+bBpLTW2xMopeqeBn0tcLk9fLc5j837Clm89QArsw4hwL6CEiYN78TGnAIKil08fHkPzunSis5xzbR5RilVbzToT1OZ28Pv31zO3My9ACRGN2F4Shxlbg/ndmnFzwfosEilVGD5FfQiMgp4BnACLxpj/lFpfjfgZaA/8KAx5il/122Msg4epVWzcMJDHNz1zkrmZu7l/tHd+Hlae2IiQ/UhHkqpBqXGoBcRJ/A8cBGQBSwTkTnGmLU+ix0AbgfG/YR1G5U9+UVc+K9vOKt1c0b1SmDOymzuuaQrt5zXOdBFU0qpKvkzjn4gsNkYs9UYUwrMBMb6LmCM2WeMWQaUneq6jYXHY8e8P/vlJtweQ2b2YZ6Yu4ERXeO49XwNeQA2z4ev/wZFBwNdEqWUD3+abhKBXT6vs4BBfm7f73VFZBIwCSApKcnPzdeP/KNljPzXN8Q3D2dDTgE3DOlA3/bRzFy6i6eu6nNmNNXs3wKhTSCqrX1tDGSlQ9u+4AyFnUvgrWvAXQJLX4Br37PzProdQppAz3GQfC5s/w5WvgVjnrLbK+d2Qc5qaNPXPvNQKVVr/An6qv7qjJ/b93tdY8x0YDpAWlqav9uvF68u2k5eYQlRTUKIighh8ogutGoWzti+iYEuWt07kgdf/RV+fBVapsCti8DhhG8ehwV/h47nQeov4PMHoUUiXPY0zPoNfP0YDPgNLP8fOEJg2Qsw4GZY9TaUHIboDnb+5vnQ7TL47B677KX/ggG/DvSnViqo+BP0WYDv0JF2QLaf2z+ddQMq/2gZCzflkhQbyYzvtzGyWzwv3phGqdtDeIgz0MWrG8bYQM/dYF+7SmD1e1BaCJ0vsKG89gMoPWJDvsM5sOMH2PaNrYlPmAEtO8PAm23Q52dBVDuYvBg+u8+GffM2kHg2fPsvWDkTDmyBiBZQnA9N4+Hzh+zBo5X3Lp1Fh2DZi9D9cojrGqAdo1Tj5k/QLwNSRKQjsBuYCFzj5/ZPZ92Amb08i/veW02p21Mx7dYRXRCR4An5Qztt6DpD4eB2OJwNGa/CqpkQ1gzE232TNBgu+gu0OgumDoFP7rJt8J1GwDXvwJ6VkL8TelwJDu86Z98EC5+CvA1w4SMQ3hzGPm8PFm362vd8boDdzmX/D1a8Ca17wfB7YOpQmHYOJA+zy//4GuSusweW1InQ7VJIucgefL78CxTmQJNou2znC6BJTGD2p1INmJTfVOukC4mMAZ7GDpGcYYx5TERuATDGTBORBCAdiAI8QCHQwxhzuKp1a3q/tLQ0k56e/tM+US2YOH0ROYdLeGJCKquz8ilze/htMI2qKToE/+wGaTfBsLvgmT42OAFGPATD7666nTxzNrz7S9tUc8W/ISS8+veY83tY8z5MWQ2RsSfO37MSIlvZ5h5fOZnw4+uw6XNb2w9vAWP/DVsXwKp3bDnjuoHHbQ9Qrc6Cw7uh+JA9OMV1twcSgGbxti8gdwOkvwQX/xVapVRd3sJ9kLMGkoZCqD6OUTU+IpJhjEmrcp4/QV/fAhn0Ho8h9dHPGd8/kf8b2ysgZahVxtjQLj4Mr4+DEQ9ASYENbGc49Bpvm1CuetmGZuueJ9/e/i0Q26nmDtPSo3AkF2I6/PSyH9hmm3XKDxSuUtj4GXzxsD0bmPiG7eD1uGF3Bmz6Avausp8ZYOdie5ZRnA/GAxHRMPh39mCxdYE9iynfR0UH7M9JQ2Dim8cfnMr3YfnPC5+CpdMBA0Nug3OngMdjO6IdIccONOXKimH567YcHc6BDkN++j5RqhonC3q9MraSrXmFFJa4SG0XHeiinL68zfDaWBj1NxtquzPg+2egRXvbPFNWZEfA9JoAPa/0b5st/TyzCYuEsNMIeYDYjse/DgmDHmOh6xhwFdsmIbCdw+0H2n++cjfAW1fbcB3xoO0kXvB3EKcN9B4DjwV48zb2oDLvQXimL3QeYZuICvbC989CVBtoN8Duxy1fQpeLwF0K8x+2fRHrPoLCvTbo2w+2B5Tul9ltz38YlkzzljUUrp8NHYed3r5R6hRojb6SWRlZ3PXuSj6/czhnNdSbjh3OtkMTa2qPfuPnsGmeDbGQcNsubzwQHmVDLCTCto9PXhK8HZ2Va+PuMtvE46ymjpO9HJa9ZM8OCu1tLUi52IZ6zlp7UBnwG9vk5XHBGxPs2UFimu0/KDoIGz6F/ZvhvPugeQJ8fCcM/C2cdy+8PMZud/wLdruVz4wOZ9sy+p4J5W2Gpq1sX0S5I3m2Qzu2oy3PqQxJzd1ot19V05vHDYd22LO22uAqhSP7oEW7099WzlqI767Db6uhNfpTsCrrEJFhzoZ7u2CPG1662AbzdbOOn3dwu/3DijvLBtWmedD7Klj9rp1/8V/h8z/Z4Y0pF9tgGvDr4A15OD4UROxZwcm07Qdjn7MHhb2rwbjttKo4Q20zz+4f7VlDeWf0iAfhw8l2CCrYPoWLHrUH52vftQeHN38O7QbaM4ecTHtgcJXAwW32jGPMk/Z3k/6y7QCPiLIHju6Xw9oPYcHjUJJvt793tT3wlB8ccjLtUNXt39kDVMsuMPLP9ve8Zha89yt7djLxLWgWd/xn+vhOO/Lq+g9s2cCOrMrbaJv6Ogy171NWDDu+tyOxspdDr5/ZTvjKB9CPbrd9NZO+rr5ZcN1HsPwNuHLa8Qez45b5GN6+1h4gU39up+Vn2ebB6n4/qoLW6CsZ9/z3hIU4eOe3DaQddePn8OWj8MtP7B/Bxs/hzasAgSmrINp7cVnpUTuSpbQAfvU5vHGVDbXfLYJP7rR/rJOXwlsTYfOXcPemE//IVe0xxvYXlBVDQi8Ia3psnrvMDhld/oa9SCyq3bELz9r0tQG66XMIjYSyo3Y0kbsMtn97bBtdLoSLH7NNb98/baclDbUHgi8fte+fNNg2R239xvZLdBgKu5baDun9W+wZSUiEPeCff589YLxzAzjDbEf5mCftAWPjZ8d/ttBIewDxuGz4x3Q4diBweIM+oTdc8jd46UJ7Ftm6t+3kz99lDzIrZ9rvYXw3WynB2I7ztv3hozts6LuKYfYtMOwPsOAf9kyjy4W2grPjB5h5jf3eT1llz5wqW/2ePQOoqd/JH+4y28/S+QKIST797dUB7Yz1U35RGQMem8+NQzrw4KU96v39q/TWNbDhE/tHPfQ2ePs62LrQ1srPuw+GTLZ/cEv+C9/8w/7hIrZj8FfzbLu1x+39ow63p+17VkLqVYH+ZApsJ3l48+PPPNwueyDI32WbPAbcbJuM9q621yzEdYeUC48tn7fJNhf98G9bw61cWz+SB4uegw1zbY37hjm2GW/NLNvUtOod+30BG8iX/hNeGWO/M+FR9myh91X2O7flazvKyRlq+zmSh9kzlQ2f2vAFG4rpM2wTmThgzBN2FJYvcUKXkbY5JvkcexYiDntg2v4txPewQX9g67F1OpxjO9ivfdf2vUS1tZ9j0G/hwkfh6H7blwL27+Gze+1Bafx0e1FeVU0+hblQkG37TuK62gPgkmn2WpFm8faspkmMHcq75UuIbAkX/MmegXUYavfBoucgf7c92Jz/R/t3VphjX+dn2T6exP72INW01fHvv/ZDu8yg3x07I/yJNOhr4PEYXl20nafnbyK/qIw3fzOIoV1anbhgSYEdCdImtX4KVnoEnuhkv/DRSbam/nQvGHSL/cPYs8KGQmmh/SPpMRY6nWdrRMPuhpF/qp9yqoahON/WjrtdevztJWpycLs9UwT7HWre2jb7uEpsuP6U4aYr3oIPbrGjki55DDbOswMAYjvCzkWQkHr8UNcl0+3V0WBDef3HgNja+/qP7dlCv2th2rn2jKNJLPzue/jiz/aA1Szehn5sJ9sntXORDdYjubZpKSoRzpkCZ//SnvFkr7BDcnPWHCtDRLT9W3KGQdM4KNhjz1zAHphGPGDPcA5us39vxmOX9bjsAfnQTug5HjB2KPJ598O6ObCv/B6OYi8WHH6PHXn1w3Ow8Ak7q+d4GPX3qs9M/KRBX0lhiYtnv9xEUakbgI05BSzZdoDhZ8Vx7yVd6ZXY4sSVDu6wzSF5G04+1hzsafO8B+yX8bx7Tl4YY2DLV/Y02xlmT52Th9lRG+s/tjX4Ab+xNbyIFlBSaG9DkLfRzjtrtG2jzFkNox63tZycTFsjOs0aglKnZd86e9uM6jq+fRUdhKe62u/4HSsh42VbMx7wm2PLGAPPD7J/g9fNskG+fwv8Z4jth0i9yjZNFR+2zUljngQE1rxnz1q2f2tHnOXvgvaD7IGnw1Dbh1J6BLYttH0h5/7Bng2VFELWUjs6LbazbWYqPmz/9uJ7wIo3bGVr8K22eei7p+0IK7BnVVnLbFPWte/as4JNX9hbgOzffOxA0ecae8D78lG7Xtv+8Osv/NtnlWjQV/LK99t45KO1FfeODw9xcOv5nblucIdjNygrOmgv3Ilqa09Zv/qrPXInDbVtlvE97JDEYXfZ02pfy9+AD2+1tYDfpx8/gsHjtkP2nKG21rDqbZj9Wzsqo+Nw2+EE0OdqexHP7gy4awNMP9+2uY/6h/1yAhTk2NqXUsFgxVv2b8K3WaqyLV/ZmvPZvzw27UierY2fLBw9HhvCy16092Pq84taKrQPY2yTUUwynHWJvblfdHvoOvrYMu4yyHjFZkCXC20FT8QeFDd8Zs8ixjz5k95eg76Ssc99R6nb8Nkd1Yxl3jQf3r/52EU0YNviLn/WHn0zXrEdPTu+s+2nFz1qf1HuMtv+/dVf7ciXvWtsLWPs83YbBXvhzV/YWgDYjp2sdHu6GBppa+Z5m6DPRNveatz2iH/lVPtF1Rq6UqfH7fpJteXGQIdX+tiSW8jKrHweHNO96gVcpfDxFFuzuOED+7rsiL3RVnltP+0m++/zh2wgZ7wCHp9b8cf3hKtesW1wy160HTjOMFvTL863wxxLj8Ki5+3p24SX4d0b7anluXfa+8OcOwV2LLKngKAhr1RtCNKQr8kZ96ln/7gbh8DYvm2Pn7Hgcdtp036AbcO7dha06XPyjV34f7Z5xl1qL8UPibDNNOVXdA6/B/Zv8ga6d7jbqL8f2+7Am21tPjoJFg+GXYuh3/V2XpMY6Damdj+8UuqMdEYEvTEGEeFIiYuZy3YyLCWO+CifkQQ5mXZoovHY9vfEs+3Qr5o4HLbZpjrN4uzl7iUF3nutVOrkjYw9dk+VS5+yHUn+3mJAKaX8dEYE/R0vzsPlCCM5sS1SmMNDPUrsZevlvnnChvC4abDgb7ZppTYvsy6/J8vJJPS2/5RSqpYFfdDnHy1lyq4prDPtmbxpCguiniF57sYTF7z0X9B1lP2nlFJBJOiDfu3alQxx7KGtI5/+zYpJLtpoR8r0Gn9sofDmWptWSgWtoA/6gswvAIjwHOX93ktgKdD3atsOr5RSZ4CgH7MXted7DkkLQOz9NyKi7Y2jlFLqDBHUQV9SWkq3ouVsbznMDmn0lNmrTytfyaqUUkEs+JpuCvbC0uls2XuIvLx9DJIjSKcRELrLXpHa6fxAl1AppepV8AX92g/h23+SSBhtDeyVViQPugxK99mbhPned0Ippc4AwRf03tuKnseLjD67C49cUf7QgQT4fUbgyqWUUgHiVxu9iIwSkQ0isllE7q9ivojIs975q0Skv8+8O0UkU0TWiMhbIvITbm59CjwuAIrdQlhIUHdBKKWUX2pMQhFxAs8Do4EewNUiUvnxS6OBFO+/ScBU77qJwO1AmjGmF+AEJtZa6aviPhb0oU59iLBSSvlT5R0IbDbGbDXGlAIzgbGVlhkLvGasxUC0iHif6UUI0EREQoBIILuWyl41b42+xCOEOXV0jVJK+RP0icAun9dZ3mk1LmOM2Q08BewE9gD5xpjPq3oTEZkkIukikp6bm+tv+U/kcWEcIYAQGqI1eqWU8ifoq0rLyk8rqXIZEYnB1vY7Am2BpiJyXVVvYoyZboxJM8akxcXF+VGsanhcFU+iD3NqG71SSvmThFlAe5/X7Tix+aW6ZS4Ethljco0xZcD7wNCfXlw/eFz2HvFAqAa9Ukr5FfTLgBQR6SgiYdjO1DmVlpkD3OAdfTMY20SzB9tkM1hEIsU+jHUksK4Wy3+iiqYbdNSNUkrhxzh6Y4xLRG4D5mFHzcwwxmSKyC3e+dOAT4ExwGbgKHCTd94SEXkP+BFwAcuB6XXxQSr4BL3W6JVSys8Lpowxn2LD3HfaNJ+fDTC5mnUfBh4+jTKeGo8LI+VBr52xSikVfFVetwvjvWlZuDbdKKVUEAa9x4VHO2OVUqpC8CXhcU03wffxlFLqVAVfEnpceDTolVKqQvAloU/TjQ6vVEqpYA96rdErpVSwBr236UbvdaOUUkEY9O4y3GiNXimlygVfEnrcuL0fSztjlVIqKINeO2OVUspX8CWhx4ULHV6plFLlgi8JPT5t9FqjV0qpYAx63zZ6HXWjlFJBGPQuXN4afagj+D6eUkqdquBLQm/QhzoFh0Nr9EopFXxB7y7DhUM7YpVSyiv40tDjxo1Tg14ppbyCLw09LsqM1uiVUqpc8KWhx0WZcerTpZRSyiv40tBTVtEZq5RSKiiD3q1NN0op5SP40tDbRq9XxSqllOVXGorIKBHZICKbReT+KuaLiDzrnb9KRPr7zIsWkfdEZL2IrBORIbX5AU7gcVFqdNSNUkqVqzENRcQJPA+MBnoAV4tIj0qLjQZSvP8mAVN95j0DzDXGdAP6AOtqodxVM8bW6D0OvRe9Ukp5+ZOGA4HNxpitxphSYCYwttIyY4HXjLUYiBaRNiISBQwHXgIwxpQaYw7VXvEr8bgBbBu9Pl1KKaUA/4I+Edjl8zrLO82fZToBucDLIrJcRF4UkaZVvYmITBKRdBFJz83N9fsDHMfjAqDMiNbolVLKy580rKpqbPxcJgToD0w1xvQDjgAntPEDGGOmG2PSjDFpcXFxfhSrCt6gL/ZoG71SSpXzJw2zgPY+r9sB2X4ukwVkGWOWeKe/hw3+uuEpA8qbbjTolVIK/Av6ZUCKiHQUkTBgIjCn0jJzgBu8o28GA/nGmD3GmL3ALhHp6l1uJLC2tgp/Am8bfal2xiqlVIWQmhYwxrhE5DZgHuAEZhhjMkXkFu/8acCnwBhgM3AUuMlnE78H3vAeJLZWmle7vE03JR5to1dKqXI1Bj2AMeZTbJj7Tpvm87MBJlez7gog7acX8RRUBL2OulFKqXLBVe112zb6Er0FglJKVQiuNKxooxe9BYJSSnkFVxqWD690a2esUkqVC640rLhgSsfRK6VUueBKQ+84en1mrFJKHRNcaehto3fj1DZ6pZTyCq409DbduHASpk+YUkopIIiDXptulFLKCq409I6jd+kTppRSqkJwpaFPG73W6JVSygquNNSmG6WUOkFwpaFvZ6ze60YppYCgC/rycfROwpzOABdGKaUahiAL+vI2egehOrxSKaWAoAt6nzZ6HXWjlFJAsAW9d3il2+hNzZRSqlxwpWH5Tc0I0XH0SinlFVxp6A16t97UTCmlKgRXGno7Y+04eu2MVUopCLqg97bRo7dAUEqpcsGVhr5t9Np0o5RSgJ9BLyKjRGSDiGwWkfurmC8i8qx3/ioR6V9pvlNElovIx7VV8Cr5tNFHhoXU6VsppVRjUWPQi4gTeB4YDfQArhaRHpUWGw2keP9NAqZWmn8HsO60S1sTbxu906mjbpRSqpw/aTgQ2GyM2WqMKQVmAmMrLTMWeM1Yi4FoEWkDICLtgEuBF2ux3FVzl+HBQWR4aJ2/lVJKNRb+BH0isMvndZZ3mr/LPA3cC3hO9iYiMklE0kUkPTc3149iVcHjwi0hNA3XZhullCrnT9BXNU7R+LOMiFwG7DPGZNT0JsaY6caYNGNMWlxcnB/FqoLHhRsHzTTolVKqgj9BnwW093ndDsj2c5lzgCtEZDu2yecCEfnfTy5tTTxu3Di1Rq+UUj78CfplQIqIdBSRMGAiMKfSMnOAG7yjbwYD+caYPcaYPxpj2hljkr3rfWWMua42P8BxPGW4cRIZprcoVkqpcjVWfY0xLhG5DZgHOIEZxphMEbnFO38a8CkwBtgMHAVuqrsin4THRRlObbpRSikffiWiMeZTbJj7Tpvm87MBJtewjQXAglMu4anwuHAZhzbdKKWUj+AabO5x49LOWKWUOk5QBb1xl1FmnDQN1zZ6pZQqF1RB76kIeq3RK6VUuaAKeperTJtulFKqkqAKerfLZcfR6w3NlFKqQlAFvcdViguHttErpZSPoAp6t6sMF3qvG6WU8hVUQe9x23vdaNArpdQxQRf0LqNXxiqllK+gCnrcZVqjV0qpSoIq6D1uF2WE0ExH3SilVIWgCvry+9HrqBullDom6ILeI05CnMH1sZRS6nQEVyJ6yhCnNtsopZSvoAp68bjBoQ8GV0opX8EV9MalNXqllKokuILe48bh1Bq9Ukr5CqqgdxgXDq3RK6XUcYIs6LVGr5RSlQVV0Dtx4wjRoFdKKV9BFfQO3Dg16JVS6jh+Bb2IjBKRDSKyWUTur2K+iMiz3vmrRKS/d3p7EflaRNaJSKaI3FHbH8DXA13nkjPwvrp8C6WUanRq7LkUESfwPHARkAUsE5E5xpi1PouNBlK8/wYBU73/u4C7jDE/ikhzIENEvqi0bq35f1efXRebVUqpRs2fGv1AYLMxZqsxphSYCYyttMxY4DVjLQaiRaSNMWaPMeZHAGNMAbAOSKzF8iullKqBP0GfCOzyeZ3FiWFd4zIikgz0A5accimVUkr9ZP4EvVQxzZzKMiLSDJgFTDHGHK7yTUQmiUi6iKTn5ub6USyllFL+8Cfos4D2Pq/bAdn+LiMiodiQf8MY8351b2KMmW6MSTPGpMXFxflTdqWUUn7wJ+iXASki0lFEwoCJwJxKy8wBbvCOvhkM5Btj9oiIAC8B64wx/6rVkiullPJLjaNujDEuEbkNmAc4gRnGmEwRucU7fxrwKTAG2AwcBW7yrn4OcD2wWkRWeKc9YIz5tFY/hVJKqWqJMZWb2wMvLS3NpKenB7oYSinVaIhIhjEmrap5QXVlrFJKqRM1yBq9iOQCO37i6q2AvFosTm3Rcp26hlo2Ldep0XKdup9Stg7GmCpHsjTIoD8dIpJe3elLIGm5Tl1DLZuW69RouU5dbZdNm26UUirIadArpVSQC8agnx7oAlRDy3XqGmrZtFynRst16mq1bEHXRq+UUup4wVijV0op5UODXimlglzQBH1NT8Gqx3JU+VQtEXlERHaLyArvvzEBKt92EVntLUO6d1qsiHwhIpu8/8fUc5m6+uyXFSJyWESmBGKficgMEdknImt8plW7f0Tkj97v3AYRuSQAZXtSRNZ7n+w2W0SivdOTRaTIZ99Nq+dyVfu7q699Vk253vYp0/byW7PU8/6qLiPq7ntmjGn0/7D34NkCdALCgJVAjwCVpQ3Q3/tzc2Aj0AN4BLi7Aeyr7UCrStOeAO73/nw/8HiAf5d7gQ6B2GfAcKA/sKam/eP9va4EwoGO3u+gs57LdjEQ4v35cZ+yJfsuF4B9VuXvrj73WVXlqjT/n8CfA7C/qsuIOvueBUuN3p+nYNUL0zifqjUWeNX786vAuMAVhZHAFmPMT70y+rQYYxYCBypNrm7/jAVmGmNKjDHbsDf1G1ifZTPGfG6McXlfLsbeIrxeVbPPqlNv++xk5fLeWffnwFt18d4nc5KMqLPvWbAEvT9Pwap3cuJTtW7znmLPqO/mER8G+FxEMkRkkndaa2PMHrBfQiA+QGUDexts3z++hrDPqts/De179yvgM5/XHUVkuYh8IyLDAlCeqn53DWWfDQNyjDGbfKbV+/6qlBF19j0LlqD35ylY9UpOfKrWVKAz0BfYgz1tDIRzjDH9sQ90nywiwwNUjhOIfd7BFcC73kkNZZ9Vp8F870TkQcAFvOGdtAdIMsb0A/4AvCkiUfVYpOp+dw1ln13N8RWKet9fVWREtYtWMe2U9lmwBL0/T8GqN1LFU7WMMTnGGLcxxgO8QB2e4p+MMSbb+/8+YLa3HDki0sZb9jbAvkCUDXvw+dEYk+MtY4PYZ1S/fxrE905EbgQuA6413kZd72n+fu/PGdh23bPqq0wn+d0FfJ+JSAgwHni7fFp976+qMoI6/J4FS9D78xSseuFt+zvhqVrlv0CvK4E1ldeth7I1FZHm5T9jO/LWYPfVjd7FbgQ+rO+yeR1Xy2oI+8yruv0zB5goIuEi0hFIAZbWZ8FEZBRwH3CFMeaoz/Q4EXF6f+7kLdvWeixXdb+7gO8z4EJgvTEmq3xCfe6v6jKCuvye1Ucvcz31ZI/B9l5vAR4MYDnOxZ5WrQJWeP+NAV4HVnunzwHaBKBsnbC99yuBzPL9BLQEvgQ2ef+PDUDZIoH9QAufafW+z7AHmj1AGbYm9euT7R/gQe93bgMwOgBl24xtvy3/rk3zLvsz7+94JfAjcHk9l6va31197bOqyuWd/gpwS6Vl63N/VZcRdfY901sgKKVUkAuWphullFLV0KBXSqkgp0GvlFJBToNeKaWCnAa9UkoFOQ16pZQKchr0SikV5P4/RNbdRGsl9TUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5b3e3a",
   "metadata": {},
   "source": [
    "# Make a sampling model\n",
    "\n",
    "Instead of using the model above that takes as input an entire sequence, we need to create a sampling model to process one word at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "460dfe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a sampling model\n",
    "input2 = Input(shape=(1,)) # we'll only input one word at a time\n",
    "x = embedding_layer(input2)\n",
    "x, h, c = lstm(x, initial_state=[initial_h, initial_c]) # now we need states to feed back in\n",
    "output2 = dense(x)\n",
    "sampling_model = Model([input2, initial_h, initial_c], [output2, h, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "452eaf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          multiple             150000      ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    multiple             7600        ['embedding[1][0]',              \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  multiple             78000       ['lstm[1][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 235,600\n",
      "Trainable params: 85,600\n",
      "Non-trainable params: 150,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sampling_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eefdf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse word2idx dictionary to get back words\n",
    "# during prediction\n",
    "idx2word = {v:k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da53aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_line():\n",
    "  # initial inputs\n",
    "  np_input = np.array([[ word2idx['<sos>'] ]])\n",
    "  h = np.zeros((1, LATENT_DIM))\n",
    "  c = np.zeros((1, LATENT_DIM))\n",
    "\n",
    "  # so we know when to quit\n",
    "  eos = word2idx['<eos>']\n",
    "\n",
    "  # store the output here\n",
    "  output_sentence = []\n",
    "\n",
    "  for _ in range(max_seq_length):\n",
    "    o, h, c = sampling_model.predict([np_input, h, c], verbose = 0)\n",
    "    #o is the list of probabilities for the next word\n",
    "    #this is where we take a sample from\n",
    "    # print(\"o.shape:\", o.shape, o[0,0,:10])\n",
    "    # idx = np.argmax(o[0,0])\n",
    "    probs = o[0,0]\n",
    "    if np.argmax(probs) == 0:\n",
    "      print(\"wtf\")\n",
    "    probs[0] = 0\n",
    "    probs /= probs.sum()\n",
    "    idx = np.random.choice(len(probs), p=probs)\n",
    "    if idx == eos:\n",
    "      break\n",
    "\n",
    "    # accuulate output\n",
    "    output_sentence.append(idx2word.get(idx, '<WTF %s>' % idx))\n",
    "\n",
    "    # make the next input into model\n",
    "    np_input[0,0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb31c849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that's 'better who keep track. might donkey's\n",
      "word as what what me so are people i it.' should, her\n",
      "someone's rain?' -\n",
      "of time as where and the stove. from the raspberry girl, because\n",
      "and think the slumbering aftermath, goblet piece arch everywhere!— weakly\n",
      "you saw to ever out the tangle\n",
      "so just to a worse too tell the some mistake. leaf, home\n",
      "she swept his doubts for muffled. where 'well back pieces four books\n",
      "---generate another? [Y/n]---y\n",
      "where driven it listened they fade,\n",
      "all claiming there mad.' times i partial song), 'you summer\n",
      "i had now i serve i seize people wheels\n",
      "to me to give of treading windows. though.\n",
      "like, that i had them, my head time to talk, he whined.\n",
      "so to piano in seven then. to felt and both find burnt-\n",
      "of there no way we'd\n",
      "and threw at his longer of cedar.\n",
      "---generate another? [Y/n]---n\n"
     ]
    }
   ],
   "source": [
    "# generate a 4 line poem\n",
    "while True:\n",
    "  for _ in range(8):\n",
    "    print(sample_line())\n",
    "\n",
    "  ans = input(\"---generate another? [Y/n]---\")\n",
    "  if ans and ans[0].lower().startswith('n'):\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
